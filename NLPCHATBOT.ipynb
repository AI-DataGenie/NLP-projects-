{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urgOzlyalTu5",
        "outputId": "c5b351d3-86f0-43b6-c81b-5f737b3f661d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import json\n",
        "import  string \n",
        "import random \n",
        "import nltk\n",
        "import numpy as np\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import tensorflow as tf \n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "nltk.download(\"punkt\") \n",
        "nltk.download(\"wordnet\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DATA**"
      ],
      "metadata": {
        "id": "DH2Xxlk6lbdZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Data = {\"Intents\": [\n",
        "\n",
        "             {\"tag\": \"dailyleave\",\n",
        "              \"patterns\": [\" how many leaves can I get in a month ?\"],\n",
        "              \"responses\": [\" you have 1 casual and 1 sick leave in a month \"]\n",
        "             },\n",
        "              {\"tag\": \"greeting\",\n",
        "              \"patterns\": [ \"Hi\", \"Hello\", \"Hey\"],\n",
        "              \"responses\": [\"Hi there\", \"Hello\", \"Hi :)\"],\n",
        "             },\n",
        "              {\"tag\": \"goodbye\",\n",
        "              \"patterns\": [ \"bye\", \"later\"],\n",
        "              \"responses\": [\"Bye\", \"take care\"]\n",
        "             },\n",
        "             {\"tag\": \"federalleaves\",\n",
        "              \"patterns\": [\"how many leaves on this Eid? \", \"Is office open on jummatulviddah\"],\n",
        "              \"responses\": [\"as per federal govt announcement there would be 4 leaves this eid \", \"this leave depend on federal govt announcement\"]\n",
        "             }\n",
        "\n",
        "]}"
      ],
      "metadata": {
        "id": "M9TC4KEolaZl"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lm = WordNetLemmatizer()\n",
        "ourClasses= []\n",
        "newWords = []\n",
        "documentX = []\n",
        "documentY = []\n",
        "for intent in Data[\"Intents\"]:\n",
        "    for pattern in intent[\"patterns\"]:\n",
        "        ournewTkns = nltk.word_tokenize(pattern)\n",
        "        newWords.extend(ournewTkns)\n",
        "        documentX.append(pattern)\n",
        "        documentY.append(intent[\"tag\"])\n",
        "    if intent[\"tag\"] not in ourClasses:\n",
        "       ourClasses.append(intent[\"tag\"])\n",
        "\n",
        "newWords = [lm.lemmatize(word.lower()) for word in newWords if word not in string.punctuation] # set words to lowercase if not in punctuation\n",
        "newWords = sorted(set(newWords))\n",
        "print(newWords)\n",
        "ourClasses = sorted(set(ourClasses))\n",
        "print(ourClasses)\n",
        "  "
      ],
      "metadata": {
        "id": "fDFXjJeHmbZK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6ace4f9-49f6-4f26-d550-3642733943e6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['a', 'bye', 'can', 'eid', 'get', 'hello', 'hey', 'hi', 'how', 'i', 'in', 'is', 'jummatulviddah', 'later', 'leaf', 'many', 'month', 'office', 'on', 'open', 'this']\n",
            "['dailyleave', 'federalleaves', 'goodbye', 'greeting']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainingData = [] \n",
        "outEmpty = [0] * len(ourClasses)\n",
        "for idx, doc in enumerate(documentX):\n",
        "    bagOfwords = []\n",
        "    text = lm.lemmatize(doc.lower())\n",
        "    for word in newWords:\n",
        "        bagOfwords.append(1) if word in text else bagOfwords.append(0)\n",
        "\n",
        "    outputRow = list(outEmpty)\n",
        "    outputRow[ourClasses.index(documentY[idx])] = 1\n",
        "    trainingData.append([bagOfwords, outputRow])\n",
        "\n",
        "random.shuffle(trainingData)\n",
        "trainingData = np.array(trainingData, dtype=object)\n",
        "\n",
        "x = np.array(list(trainingData[:, 0]))\n",
        "y = np.array(list(trainingData[:, 1]))\n"
      ],
      "metadata": {
        "id": "HHkhXpx8nHrh"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iShape = (len(x[0]),)\n",
        "oShape = len(y[0])\n",
        "ourNewModel = Sequential()\n",
        "\n",
        "ourNewModel.add(Dense(128, input_shape=iShape, activation=\"relu\"))\n",
        "ourNewModel.add(Dropout(0.5))\n",
        "ourNewModel.add(Dense(64, activation=\"relu\"))\n",
        "ourNewModel.add(Dropout(0.3))\n",
        "ourNewModel.add(Dense(oShape, activation = \"softmax\"))\n",
        "md = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
        "ourNewModel.compile(loss='categorical_crossentropy',\n",
        "              optimizer=md,\n",
        "              metrics=[\"accuracy\"])\n",
        "print(ourNewModel.summary())\n",
        "ourNewModel.fit(x, y, epochs=100, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNYDqf5pnlKJ",
        "outputId": "5c01d3ff-792e-444d-8a42-3af9f272ff76"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_6 (Dense)             (None, 128)               2816      \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 4)                 260       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11,332\n",
            "Trainable params: 11,332\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 1s 872ms/step - loss: 1.4940 - accuracy: 0.1250\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.2941 - accuracy: 0.3750\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.1500 - accuracy: 0.5000\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.9637 - accuracy: 0.6250\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.8966 - accuracy: 0.7500\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.9481 - accuracy: 0.7500\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.9785 - accuracy: 0.7500\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6214 - accuracy: 1.0000\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.5759 - accuracy: 1.0000\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4673 - accuracy: 1.0000\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3291 - accuracy: 0.8750\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3119 - accuracy: 1.0000\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2882 - accuracy: 1.0000\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1996 - accuracy: 1.0000\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1401 - accuracy: 1.0000\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1708 - accuracy: 1.0000\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1260 - accuracy: 1.0000\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1049 - accuracy: 1.0000\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0540 - accuracy: 1.0000\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0265 - accuracy: 1.0000\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0381 - accuracy: 1.0000\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0045 - accuracy: 1.0000\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0055 - accuracy: 1.0000\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0237 - accuracy: 1.0000\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0123 - accuracy: 1.0000\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0297 - accuracy: 1.0000\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0199 - accuracy: 1.0000\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0048 - accuracy: 1.0000\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0046 - accuracy: 1.0000\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0030 - accuracy: 1.0000\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.5916e-04 - accuracy: 1.0000\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0027 - accuracy: 1.0000\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0030 - accuracy: 1.0000\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.2447e-05 - accuracy: 1.0000\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 8.2751e-05 - accuracy: 1.0000\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.2176e-04 - accuracy: 1.0000\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.0148e-04 - accuracy: 1.0000\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.9369e-04 - accuracy: 1.0000\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.1186e-04 - accuracy: 1.0000\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.0205e-05 - accuracy: 1.0000\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0019 - accuracy: 1.0000\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0038 - accuracy: 1.0000\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.7580e-04 - accuracy: 1.0000\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0017 - accuracy: 1.0000\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.4069e-05 - accuracy: 1.0000\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.7919e-04 - accuracy: 1.0000\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.6900e-04 - accuracy: 1.0000\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.6296e-05 - accuracy: 1.0000\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0061 - accuracy: 1.0000\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0205 - accuracy: 1.0000\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.8981e-05 - accuracy: 1.0000\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.3304e-04 - accuracy: 1.0000\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.2010e-05 - accuracy: 1.0000\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 4.2766e-06 - accuracy: 1.0000\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.3295e-06 - accuracy: 1.0000\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.4338e-05 - accuracy: 1.0000\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.5432e-06 - accuracy: 1.0000\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.9035e-04 - accuracy: 1.0000\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.0812e-06 - accuracy: 1.0000\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.5974e-05 - accuracy: 1.0000\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.0624e-04 - accuracy: 1.0000\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0034 - accuracy: 1.0000\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.9807e-04 - accuracy: 1.0000\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.1094e-06 - accuracy: 1.0000\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 8.1257e-04 - accuracy: 1.0000\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0045 - accuracy: 1.0000\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.4300e-05 - accuracy: 1.0000\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.6654e-04 - accuracy: 1.0000\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.3939e-05 - accuracy: 1.0000\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.3683e-04 - accuracy: 1.0000\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.2418e-06 - accuracy: 1.0000\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 9.2832e-06 - accuracy: 1.0000\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.5879e-06 - accuracy: 1.0000\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.5881e-05 - accuracy: 1.0000\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.4960e-04 - accuracy: 1.0000\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.8641e-04 - accuracy: 1.0000\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 9.4174e-06 - accuracy: 1.0000\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.0792e-05 - accuracy: 1.0000\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.9212e-04 - accuracy: 1.0000\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.1395e-04 - accuracy: 1.0000\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.9859e-04 - accuracy: 1.0000\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.6016e-04 - accuracy: 1.0000\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.1525e-07 - accuracy: 1.0000\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.2404e-05 - accuracy: 1.0000\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.3881e-05 - accuracy: 1.0000\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.0607e-05 - accuracy: 1.0000\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 8.5085e-06 - accuracy: 1.0000\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.1131e-05 - accuracy: 1.0000\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.7918e-05 - accuracy: 1.0000\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 3.1945e-04 - accuracy: 1.0000\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.7352e-06 - accuracy: 1.0000\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.5779e-06 - accuracy: 1.0000\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.5950e-05 - accuracy: 1.0000\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.2402e-06 - accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f999fd30fa0>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ourText(text):\n",
        "  newtkns = nltk.word_tokenize(text)\n",
        "  newtkns = [lm.lemmatize(word) for word in newtkns]\n",
        "  return newtkns\n",
        "\n",
        "def wordBag(text, vocab):\n",
        "  newtkns = ourText(text)\n",
        "  bagOwords = [0] * len(vocab)\n",
        "  for w in newtkns:\n",
        "    for idx, word in enumerate(vocab):\n",
        "      if word == w:\n",
        "        bagOwords[idx] = 1\n",
        "  return np.array(bagOwords)\n",
        "\n",
        "def Pclass(text, vocab, labels):\n",
        "  bagOwords = wordBag(text, vocab)\n",
        "  ourResult = ourNewModel.predict(np.array([bagOwords]))[0]\n",
        "  newThresh = 0.2\n",
        "  yp = [[idx, res] for idx, res in enumerate(ourResult) if res > newThresh]\n",
        "\n",
        "  yp.sort(key=lambda x: x[1], reverse=True)\n",
        "  newList = []\n",
        "  for r in yp:\n",
        "    newList.append(labels[r[0]])\n",
        "  return newList\n",
        "\n",
        "def getRes(firstlist, fJson):\n",
        "  tag = firstlist[0]\n",
        "  listOfIntents = fJson[\"Intents\"]\n",
        "  for i in listOfIntents:\n",
        "    if i[\"tag\"] == tag:\n",
        "      Result = random.choice(i[\"responses\"])\n",
        "      break\n",
        "  return Result"
      ],
      "metadata": {
        "id": "5o7uAvHwnzyQ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    newMessage = input(\"\")\n",
        "    intents = Pclass(newMessage, newWords, ourClasses)\n",
        "    ourResult = getRes(intents , Data)\n",
        "    print(ourResult)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXvYEa_5oVPi",
        "outputId": "cfded17d-a90a-4935-b41e-698cf6a96bd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 23ms/step\n",
            "Hi there\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            " you have 1 casual and 1 sick leave in a month \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EPV3Bk7qvU2X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YbFkZOFboZp4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}